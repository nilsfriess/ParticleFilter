\section*{Introduction}\label{sec:intro}
In this report we present a Particle Filter library written in
C++. Before discussing the actual implementation we give the
theoretical details of the following sections.

We remark here that the naming in these methods is ambiguous and
varies from author to author and even in different publications of the
same authors. We use -- with some exceptions -- the naming and
notation used by Doucet and Johansen in~\cite{doucet} and highlight
parts where the naming differs from other publications.

\subsection*{Mathematical Formulation of the Model}
A Particle Filter is a Sequential Monte Carlo (SMC)
method\footnote{Some authors use the terms \emph{Particle Filter} and
  \emph{SMC method} synonymously. Doucet and Johansen develop
  in~\cite{doucet} a framework in which Particle Filters are only one
  specific method in the much broader class of SMC methods. They argue
  that this distinction allows for a better understanding of these
  methods. In this report, we are only interested in the
  \emph{filtering problem} and we will introduce it without discussing
  the more general notion of SMC methods as given by Doucet and
  Johansen.} that is used to estimate the state of a system that
changes over time using only noisy and/ or partial observations of the
system's state. This is done in a Bayesian framework where one
attempts to construct the posterior probability density function (pdf)
of the state based on the observations. We make the following
assumptions:
\begin{enumerate}[label=(A\arabic*)]
\item A model describing the initial state and the evolution of the
  internal state in time is available in a probabilistic form.
\item A model that relates the observations to the internal state is
  available in a probabilistic form.
\item The observations are only available sequentially, not as a batch
  (\ie, we assume that we receive new measurements sequentially in
  time).
\end{enumerate}
Due to (A3) we aim at a recursive method that does neither require to
store nor to reprocess all the previous information when a new
observation becomes available. To formalise the first two assumptions
we will use the notion of \emph{hidden Markov models}.

Such models consist of the triplet
\begin{align*}
  \label{eq:hmm:1}
  X_0 &\sim p(x_0)\,,\\
  X_n \mid (X_{n-1} = x_{n-1}) &\sim p(x_n \mid x_{n-1})\,,\\
  Y_n \mid (X_n = x_n) &\sim p(y_n \mid x_n) \,,
\end{align*}
where
\begin{itemize}
\item $n \in \N$ denotes discrete time;
\item $X_n$ is the $d_x$-dimensional state of the system taking values
  in $\R^{d_x}$;
\item $p(x_0)$ is the prior probability density function (pdf) of the
  system's state;\footnote{ With abuse of notation we denote by $p(x)$
    the pdf of the random variable $X$. For two random variables $X$
    and $Y$ the corresponding (possibly different) density functions
    are denoted by $p(x)$ and $p(y)$ respectively; $p(x,y)$ denotes
    the joint pdf and $p(x \mid y)$ is the conditional pdf of $X$
    given $Y = y$.}
\item $Y_n$ is the $d_y$-dimensional vector of observations which is
  assumed to be conditionally independent of all other observations
  given the state $X_n$;
\item $p(y_n \mid x_n)$ is the conditional pdf of $Y_n$ given
  $X_n = x_n$.
\end{itemize}
Assumptions (A1) and (A2) then state that all these pdfs are known.
Our goal is now to estimate the distribution $p(x_n \mid y_{1:n})$,
where $y_{1:n} \coloneqq (y_1, y_2, \dotsc, y_n)$. This is often
referred to as the \emph{filtering problem} or
\emph{tracking}.\footnote{Note that Doucet and Johansen \emph{do not}
  call this the filtering problem~\cite{doucet}. They reserve this
  term for the estimation of the joint distributions
  $p(x_{1:n} \mid y_{1:n} )$. Since we are only concerned with
  estimating the marginal distribution $p(x_n \mid y_{1:n} )$ we will
  still refer to this problem as filtering which is in accordance with
  many other publications, see for example~\cite{arulampalam, Doucet2000} or
  the more recent publication~\cite{murray}.}  In a restrictive set of
cases this distribution can be computed exactly (\eg for linear
Gaussian models or when the underlying state space of the Markov model
is finite, cf.~\cite[Example 1 and 2]{doucet}). In a more general
nonlinear non-Gaussian setting, approximative methods such as particle
filters are necessary.
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"  
%%% End:
